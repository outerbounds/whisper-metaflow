{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "78c5fb24",
   "metadata": {},
   "source": [
    "# Whisper and Metaflow\n",
    "This notebook demonstrates how to use Whisper to extract text from a YouTube video.\n",
    "The content is based on this [blog post](https://outerbounds.com/blog/mlops-whisper-and-metaflow/)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ec248b8c-fee0-472f-8a7c-e9d65b4be936",
   "metadata": {},
   "source": [
    "# Example 1: Fly Me to the Moon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e01f255-9398-4a55-af3c-f9a0c6132534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_utils import make_task\n",
    "from nlp_utils import Mixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1566d81b-d5a5-473c-8683-2dd96924bed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=ZEcqHA7dbwM\"  # paste any YouTube URL\n",
    "model_type = \"small\"\n",
    "transcription_task = make_task(url, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d55424-a17f-4eac-aa2d-dce76bec3d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nlp_tools = Mixin()\n",
    "transcription = nlp_tools.transcribe_video(transcription_task, quiet=True)\n",
    "transcription"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0359514-c91d-4ce7-b6df-2fd81c70f1e6",
   "metadata": {},
   "source": [
    "# Example 2: Charlie Bit My Finger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2daf25-cbc5-49a8-8c57-f0f9fb5ee5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.youtube.com/watch?v=0EqSXDwTq6U\"\n",
    "model_type = \"tiny\"\n",
    "transcription_task = make_task(url, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f706d9-ff42-4f06-8f08-38e10c6af52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "nlp_tools = Mixin()\n",
    "transcription = nlp_tools.transcribe_video(transcription_task, quiet=True)\n",
    "transcription"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2672e55f-163d-4f43-bd2e-c6ed0fcbc934",
   "metadata": {},
   "source": [
    "# Example 3: Fireside Chat #1\n",
    "* Video Time: 02:21:10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361a312a-a8c3-4645-80ce-fe02d1294396",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "url = \"https://www.youtube.com/watch?v=Dr6DsWa6Dhg\"\n",
    "model_type = \"tiny\"\n",
    "transcription_task = make_task(url, model_type)\n",
    "fs_chat_transcription = nlp_tools.transcribe_video(transcription_task)\n",
    "fs_chat_transcription"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f22bd25-643c-4d84-adbe-ca638db1424d",
   "metadata": {},
   "source": [
    "# Running Flows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f162e-e53e-474b-858f-69a70a079578",
   "metadata": {},
   "source": [
    "## Transcribe one Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb6605e-d14f-4766-af7f-eecbdfa93629",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python youtube_video_transcriber.py run --url 'https://www.youtube.com/watch?v=ZEcqHA7dbwM'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9ceda2-61da-4942-a1bc-3eae82258338",
   "metadata": {},
   "source": [
    "## Transcribe each Video in a Playlist\n",
    "\n",
    "[This url](https://www.youtube.com/playlist?list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc) goes to the playlist for Ville's [tagging blog](/blog/five-ways-to-use-the-new-metaflow-tags/). The playlist consists of 5 videos:\n",
    "* [Basic Tagging](https://www.youtube.com/watch?v=DEmKaTI3MG4&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=1): 05:41\n",
    "* [Programmatic Tagging](https://www.youtube.com/watch?v=25Hqp43J37I&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=2): 04:52\n",
    "* [Tags and Namespaces](https://www.youtube.com/watch?v=ifARsmiSNhE&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=3): 10:34\n",
    "* [Tags in CI/CD](https://www.youtube.com/watch?v=hIiDXPHqEFM&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=4): 03:28\n",
    "* [Tags and Continuous Training](https://www.youtube.com/watch?v=lZhwhuG0AN8&list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc&index=5): 04:33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80592d-1606-48ce-b19a-a3c5294ee8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python youtube_video_transcriber.py run \\\n",
    "    --url 'https://www.youtube.com/playlist?list=PLUsOvkBBnJBc1fcDQEOPJ77pMcE4CnNxc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f946db52-0d4b-42ce-b275-a6019453784f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis\n",
    "from metaflow import Flow\n",
    "\n",
    "run = Flow(\"YouTubeVideoTranscription\").latest_successful_run\n",
    "run.data.results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c48f5d4-ff73-48cc-94f1-5f2dc75ec42b",
   "metadata": {},
   "source": [
    "## Transcribe a List of Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6344c36b-599c-4bb6-9053-332800391286",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python youtube_video_transcriber.py run --urls 'science_video_urls.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaab3c3-a302-4a31-be63-4f2d4168e9c0",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02265c1c-b405-414f-8818-81f43fb1cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from metaflow import Flow\n",
    "\n",
    "run = Flow(\"YouTubeVideoTranscription\").latest_successful_run\n",
    "import humanize\n",
    "\n",
    "msg = \"Latest successful run was completed {}\".format(\n",
    "    humanize.naturaltime(dt.datetime.now() - run.created_at)\n",
    ")\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04341065-66a5-424f-8599-f4b034a9d4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3cf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run.data.documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff92f38f-2598-494a-a8f5-f6763948c593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gather text from each example\n",
    "# this will aggregate results in the postprocess step\n",
    "text = \" \".join(v.strip() for v in run.data.documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265d2cbd-1bd2-4856-b515-4b6c9122ea56",
   "metadata": {},
   "source": [
    "##  Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17e604f-80af-4176-8e8c-e29753540ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_gradient_magnitude\n",
    "from wordcloud import WordCloud, ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f166203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nlp_tools.aggregate_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801c2f91-8f5a-46b0-91a7-49106e674ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(\n",
    "    max_words=50,\n",
    "    max_font_size=40,\n",
    "    background_color=\"white\",\n",
    "    stopwords=stopwords,\n",
    "    random_state=42,\n",
    ").generate(text)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.axis(\"off\")\n",
    "ax.imshow(wordcloud, interpolation=\"bilinear\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c952d9a-350c-490b-8fcb-b410f24a3d18",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30381d4c-a586-4584-9e67-679dd1c3740a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "\n",
    "def get_sentences(document):\n",
    "    \"Return list of lists with inner list as each word in a sentence.\"\n",
    "    return [\n",
    "        list(\n",
    "            map(\n",
    "                lambda s: s.lower(),\n",
    "                sentence.strip()\n",
    "                .translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "                .split(),\n",
    "            )\n",
    "        )\n",
    "        for sentence in document.split(\".\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3288ab8d-ba37-40d2-91a0-58a09f43e49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwordless_document = [\n",
    "    list(filter(lambda word: word not in stopwords, sentence))\n",
    "    for sentence in get_sentences(text)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c04afa-d5bb-43f8-8f34-d751da5a908f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from matplotlib import pyplot\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "SEED = 33\n",
    "MIN_COUNT = 5\n",
    "PCA_COMPONENTS = 2\n",
    "fs_chat_id = 1\n",
    "\n",
    "model = Word2Vec(stopwordless_document, min_count=MIN_COUNT, seed=SEED)\n",
    "words = list(model.wv.index_to_key)  # vocabulary\n",
    "model.save(\"model.bin\")  # save model\n",
    "new_model = Word2Vec.load(\"model.bin\")  # load model\n",
    "X = model.wv[model.wv.index_to_key]\n",
    "\n",
    "pca = PCA(n_components=PCA_COMPONENTS, random_state=SEED)  # dim reduction\n",
    "result = pca.fit_transform(X)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "ax.scatter(result[:, 0], result[:, 1])\n",
    "for i, word in enumerate(list(model.wv.index_to_key)):\n",
    "    ax.annotate(word, xy=(result[i, 0] + 5e-4, result[i, 1] + 5e-4), rotation=0)\n",
    "ax.spines[[\"top\", \"right\", \"left\", \"bottom\"]].set_visible(False)\n",
    "ax.set_title(\"Fireside Chat {} Projected by Word2Vec\".format(fs_chat_id), y=1.04)\n",
    "pyplot.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "60d98827d7482d2a0f6aae287a18990d3a1d423e0f66197ec6cdef8a2e07b41f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
